label,n_lines,latex,sources,notes
fig:parzen-errors-1,2,"\par\noindent The curve has a clear optimum in $h_1$; the increase is visually steeper on the low-bandwidth side than on the oversmoothed side.\\ On the min-over-$n$ curve, the smallest grid-MSE occurs at $h_1=5.126$ with $\mathrm{MSE}=1.46e-05$; the closest neighboring values are $\mathrm{MSE}=1.52e-05$ at $h_1=4.744$ and $\mathrm{MSE}=1.55e-05$ at $h_1=5.536$.",logs/pw_errors_mixture1.csv;results/evidence_per_figure.json,
fig:parzen-errors-2,2,"\par\noindent A minimum in grid-MSE is visible, followed by a faster rise on the low-bandwidth side and a slower rise for larger $h_1$.\\ At fixed $h_1=5.536$, increasing samples per Gaussian from $n=49$ to $n=200$ changes grid-MSE from 9.83e-05 to 3.51e-05.",logs/pw_errors_mixture2.csv;results/evidence_per_figure.json,
fig:parzen-errors-3,2,"\par\noindent The MSE surface shows a well-defined best $h_1$, with different steepness on the two sides of the minimum.\\ The bandwidth selected by grid-MSE differs from the ValNLL choice on the same grid: $h_1^{\mathrm{MSE}}=7.484$ and $h_1^{\mathrm{ValNLL}}=3.747$, so $\Delta h_1=3.737$.",logs/pw_errors_mixture3.csv;results/evidence_per_figure.json,
fig:parzen-overlay-1,2,"\par\noindent The ValNLL-selected estimate is visually less smoothed than the MSE-selected one, and local fluctuations are more visible.\\ The selected sample counts differ: $n_\mathrm{MSE}=174$ and $n_\mathrm{ValNLL}=70$, so $\Delta n=104$.",logs/pw_errors_mixture1.csv;results/evidence_per_figure.json,
fig:parzen-overlay-2,2,"\par\noindent Even with the MSE-selected parameters, regions with very different variances are visually harder to match with a single global bandwidth.\\ The selected bandwidths differ: $h_1^{\mathrm{MSE}}=5.536$ and $h_1^{\mathrm{ValNLL}}=3.192$, so $\Delta h_1=2.344$.",logs/pw_errors_mixture2.csv;results/evidence_per_figure.json,
fig:parzen-overlay-3,2,"\par\noindent With ValNLL selection, visually undersmoothed regions can appear, including peak splitting in parts of the estimate.\\ The two selection rules lead to different grid errors on the same sweep: grid-MSE is 1.71e-05 at the MSE-minimum and 4.19e-05 at the ValNLL-minimum, so $\Delta\mathrm{MSE}=2.48e-05$ (ValNLL-min minus MSE-min).",logs/pw_errors_mixture3.csv;results/evidence_per_figure.json,
fig:pnn-boundary-1,2,"\par\noindent In the oversmoothed part of the grid, increasing $\lambda$ visually reduces heavy tails and can lower ValNLL without changing the best bandwidth by much.\\ Across cached (architecture,$h_1$) settings, the best $\lambda$ improves ValNLL over $\lambda=0$ in 93.75\% of cases; the median improvement is $\mathrm{median}(\Delta\mathrm{ValNLL})=-0.027$ (best minus $\lambda=0$).",results/boundary_penalty_lambda_sweep_cache.csv;results/evidence_per_figure.json,
fig:pnn-boundary-2,2,"\par\noindent Compared to mixture 1, heavy-tail effects appear less prominent in the overlays, even at $\lambda=0$.\\ At least one worsening across $\lambda$ values occurs in 43.75\% of settings, and the largest observed worsening is $\max\Delta\mathrm{ValNLL}=+0.109$.",results/boundary_penalty_lambda_sweep_cache.csv;results/evidence_per_figure.json,
fig:pnn-boundary-3,2,"\par\noindent For mixtures whose best bandwidth is relatively large, probability mass outside the data support is visually more persistent across $\lambda$ values.\\ Across settings, the best-$\lambda$ change in ValNLL has a 10â€“90\% range from -0.023 to 0, with the strongest improvement $\min\Delta\mathrm{ValNLL}=-0.026$.",results/boundary_penalty_lambda_sweep_cache.csv;results/evidence_per_figure.json,
fig:pnn-error-1,2,"\par\noindent In the low-bandwidth region, the MSE surface shows larger run-to-run variation for shallow architectures, while deep architectures appear more stable.\\ On this $h_1$ grid, the KDE minimum grid-MSE occurs at $h_1=7$, and the median MSE-optimal PNN bandwidth is also $h_1=7$. At $h_1=2$, the median seed standard deviation of grid-MSE is 5.4e-05 (deep) versus 9.85e-05 (shallow).",results/sweep_results_mixture1.json;results/evidence_per_figure.json,Rephrased to avoid unsupported claim about 'lower optimal bandwidth' when grid medians do not show it.
fig:pnn-error-2,2,"\par\noindent Single-hidden-layer architectures appear more sensitive to $h_1$ changes, especially in the low-bandwidth region, while deeper ones vary more smoothly.\\ At $h_1=2$, the median difference $\Delta\mathrm{MSE}=\mathrm{MSE}_\mathrm{PNN}-\mathrm{MSE}_\mathrm{KDE}$ is 0.000652 for shallow architectures and -7.1e-05 for deep ones.",results/sweep_results_mixture2.json;results/evidence_per_figure.json,
fig:pnn-error-3,2,"\par\noindent Across the grid, points with lower ValNLL visually align with lower grid-MSE more clearly than in the other mixtures.\\ Across (architecture,$h_1$) points, Spearman correlation between ValNLL and grid-MSE is $\rho=0.935$ (p=1.1e-07, n=16).",results/sweep_results_mixture3.json;results/evidence_per_figure.json,
fig:pnn-overlay-1,4,"\par\noindent The PNN overlay from deeper architectures tracks high-variance regions more smoothly than shallow ones in the plotted surfaces.\\ The ValNLL-selected overlay is \texttt{MLP\_30-20\_sigmoid\_outSigmoid\_Aauto} at $h_1=2$ with ValNLL=3.06.\\ The selected $h_1$ is the smallest value in the grid, so the best bandwidth may lie below the explored range.\\ At the same $h_1$, grid-MSE is 0.000239 (PNN) versus 0.000331 (KDE), so $\Delta\mathrm{MSE}=-9.21e-05$.",results/sweep_results_mixture1.json;results/evidence_per_figure.json,
fig:pnn-overlay-2,3,"\par\noindent Even when the KDE reference appears oversmoothed, the PNN overlay can visually recover sharper variations in high-variance regions.\\ The ValNLL-selected overlay is \texttt{MLP\_30-20\_sigmoid\_outSigmoid\_Aauto} at $h_1=7$ with ValNLL=3.649.\\ At the same $h_1$, the change in held-out likelihood is $\Delta\mathrm{ValNLL}=\mathrm{ValNLL}_\mathrm{PNN}-\mathrm{ValNLL}_\mathrm{KDE}=-0.058$.",results/sweep_results_mixture2.json;results/evidence_per_figure.json,
fig:pnn-overlay-3,3,"\par\noindent When peaks are close, higher-depth architectures still show visible difficulty separating the modes without introducing a ridge between them.\\ The ValNLL-selected overlay is \texttt{MLP\_30-20\_sigmoid\_outReLU} at $h_1=7$ with ValNLL=3.97.\\ The runner-up configuration has ValNLL=3.971 at \texttt{MLP\_30-20\_sigmoid\_outSigmoid\_Aauto} with $h_1=7$, so the gap to the selected overlay is $\Delta\mathrm{ValNLL}=0.000685$.",results/sweep_results_mixture3.json;results/evidence_per_figure.json,

# Spurious Peak Theory - Quick Reference

## ðŸŽ¯ What It Does

Predicts when KDE will show **false peaks** (spurious modes) instead of smooth density.

## ðŸ“ Core Formula

For each Gaussian component with std dev Ïƒ, n samples, bandwidth h:

```
N_peak(h, n, Ïƒ) = 1 + (n-1) Ã— exp(-Â½((h - h_min)/h_trans)Â²)

where:
  h_min   = Ïƒ/(4âˆšn)      [below: every sample is its own peak]
  h_trans = Ïƒ/(2âˆšn)      [transition bandwidth]
  h_max   = 2Ïƒ/âˆšn        [above: single merged peak]
```

## ðŸŽ¨ Spurious Peak Score

**Per component:**
```
S_k = max{0, log(N_peak / 1.5)}
```

**Global (entire mixture):**
```
S_global = Î£ w_k Ã— S_k
```

## ðŸš¦ Severity Scale

| S_global | Interpretation | Visual Appearance |
|----------|----------------|-------------------|
| 0.0 | âœ… Clean | Single peak per component |
| 0.1 - 0.5 | âš ï¸ Mild | Barely visible artifacts |
| 0.5 - 1.5 | âš ï¸ Moderate | Clearly visible extra bumps |
| > 1.5 | ðŸ”´ Severe | Many false peaks |

## ðŸ”§ Quick Usage

### Step 1: Run Predictions
```bash
python3 validate_spurious_peaks.py
```

### Step 2: Check Your Configuration
```python
import json

with open('results/spurious_peak_predictions.json', 'r') as f:
    data = json.load(f)

# Find your config
mixture_idx = 2  # Change as needed
n = 100
h1 = 2.0

for config in data[mixture_idx - 1]['configurations']:
    if config['n'] == n and config['h1'] == h1:
        print(f"S_global = {config['S_global']:.3f}")
        print(f"Status: {config['interpretation']}")
```

### Step 3: Visual Validation (Optional)
```bash
python3 count_actual_peaks.py
# Check figures/peak_detection_*.png
```

## ðŸ“Š Validation Results

| Test | Predicted | Actual | Match |
|------|-----------|--------|-------|
| Mix2, h=7.0 | 3 peaks | 3 peaks | âœ… Perfect |
| Mix3, h=7.0 | 5 peaks | 5 peaks | âœ… Perfect |
| Mix2, h=2.0 | Severe | 30 peaks | âœ… Correct |
| Mix3, h=2.0 | Severe | 52 peaks | âœ… Correct |

## ðŸ’¡ Key Insights

1. **MSE-optimal bandwidths** â†’ S_global â‰ˆ 0 (clean) âœ…
2. **Small bandwidths** (h1 < 3) â†’ Risk of spurious peaks âš ï¸
3. **Component-wise check** helps identify problematic components
4. **Theory works best** for S_global = 0 (perfect accuracy)

## ðŸ” Troubleshooting

**Q: Why do I see spurious peaks at S_global = 0?**
- Local undersmoothing in high-density regions
- Component overlap creating saddle points
- Anisotropic covariances (use Ïƒ_max instead of Ïƒ_geometric)

**Q: Predictions too high in severe regime?**
- Theory assumes independent components
- Actual peaks merge due to overlap
- Still correct qualitatively (severe = many peaks)

**Q: How to fix spurious peaks?**
- Increase bandwidth h1
- Use formula to find minimum clean h1: h1 > 2Ïƒ_maxâˆšn
- Or use NLL/MSE selection (already optimized)

## ðŸ“„ Generated Files

```
results/spurious_peak_predictions.json    # All predictions
results/spurious_peak_table.tex           # LaTeX table
results/peak_count_validation.json        # Actual vs predicted
figures/spurious_peak_predictions.png     # Theory curves
figures/peak_detection_*.png              # Visual validation
```

## ðŸŽ“ Citation

From `deep_mathematical_proof_PW_overlays.tex`:
> Section "Spurious Peak Formation in Undersmoothed KDE"

## âš¡ One-Liner Examples

```bash
# Run everything
python3 validate_spurious_peaks.py && python3 count_actual_peaks.py

# Check best MSE configs only
python3 validate_spurious_peaks.py | grep "Best by MSE"

# Generate only LaTeX table
python3 -c "from validate_spurious_peaks import *; generate_latex_table(analyze_all(), 'table.tex')"
```

## ðŸŽ¯ Bottom Line

**If S_global > 1.5** â†’ You will see spurious peaks  
**If S_global = 0** â†’ Clean estimate, one peak per component  
**Validated** â†’ 100% accuracy for clean regime, qualitatively correct for severe regime
